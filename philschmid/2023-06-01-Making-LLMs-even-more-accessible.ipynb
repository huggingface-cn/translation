{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å¤§æ¨¡å‹è®­ç»ƒï¼Œæœ‰å¡å°±è¡Œï¼bitsandbytesã€4 ä½é‡åŒ–å’Œ QLoRA æŠ€æœ¯åŸç†ä¸åº”ç”¨\n",
    "\n",
    "\n",
    "\n",
    "åœ¨æ¶ˆè´¹ç¡¬ä»¶ä¸Šè¿è¡Œæˆ–è®­ç»ƒLLMs å¯¹ç”¨æˆ·æ˜¯ä¸€ä¸ªå·¨å¤§çš„æŒ‘æˆ˜ã€‚æˆ‘ä»¬çš„ [LLM.int8 åšå®¢æ–‡ç« ](https://huggingface.co/blog/hf-bitsandbytes-integration) å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ `bitsandbytes` åº“å°† [LLM.int8 è®ºæ–‡](https://arxiv.org/abs/2208.07339) ä¸­çš„æŠ€æœ¯é›†æˆåˆ° transformers ä¸­ã€‚ä¸ºäº†ä½¿æ¨¡å‹æ›´åŠ æ˜“äºè¿è¡Œï¼Œæˆ‘ä»¬å†æ¬¡ä¸ bitsandbytes åˆä½œï¼Œè®©ç”¨æˆ·ä»¥ 4 ä½ç²¾åº¦è¿è¡Œæ¨¡å‹ã€‚è¿™åŒ…æ‹¬å¤§å¤šæ•° HF æ¨¡å‹ï¼Œæ— è®ºæ˜¯ä»€ä¹ˆæ¨¡æ€ï¼ˆæ–‡æœ¬ã€è§†è§‰ã€å¤šæ¨¡æ€ç­‰ï¼‰ã€‚ç”¨æˆ·è¿˜å¯ä»¥ä½¿ç”¨ Hugging Face ç”Ÿæ€ç³»ç»Ÿä¸­çš„å·¥å…·åœ¨ 4 ä½æ¨¡å‹ä¹‹ä¸Šè®­ç»ƒé€‚é…å™¨ã€‚è¿™æ˜¯ Dettmers ç­‰äººåœ¨ QLoRA è®ºæ–‡ä¸­ä»Šå¤©ä»‹ç»çš„ä¸€ç§æ–°æ–¹æ³•ã€‚è¯¥è®ºæ–‡çš„æ‘˜è¦å¦‚ä¸‹ï¼š\n",
    "\n",
    "```\n",
    "    ä½œè€…æå‡ºäº†QLoRAï¼Œè¿™æ˜¯ä¸€ç§é«˜æ•ˆçš„å¾®è°ƒæ–¹æ³•ï¼Œå¯ä»¥å°†å†…å­˜ä½¿ç”¨é™ä½åˆ°åœ¨å•ä¸ª48GB GPUä¸Šå¾®è°ƒ65Bå‚æ•°æ¨¡å‹ï¼ŒåŒæ—¶ä¿æŒå®Œæ•´çš„16ä½å¾®è°ƒä»»åŠ¡æ€§èƒ½ã€‚*QLoRA é€šè¿‡å†»ç»“çš„ 4 ä½é‡åŒ–é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹å°†æ¢¯åº¦åå‘ä¼ æ’­åˆ°ä½é˜¶é€‚é…å™¨(LoRA)*ã€‚æœ€å¥½çš„æ¨¡å‹ç³»åˆ—åä¸ºGuanacoï¼ˆåŸé©¼ï¼‰ï¼Œä¼˜äºæ‰€æœ‰ä»¥å‰å…¬å¼€å‘å¸ƒçš„æ¨¡å‹ï¼Œå¹¶åœ¨VicunaåŸºå‡†æµ‹è¯•ä¸­è¾¾åˆ°äº†ChatGPTæ€§èƒ½æ°´å¹³çš„99.3%ï¼Œè€Œåªéœ€è¦åœ¨å•ä¸ªGPUä¸Šè¿›è¡Œ24å°æ—¶çš„å¾®è°ƒã€‚QLoRAå¼•å…¥äº†å¤šé¡¹åˆ›æ–°ï¼Œåœ¨ä¸æŸå¤±æ€§èƒ½ä¸‹èŠ‚çœå†…å­˜ï¼šï¼ˆaï¼‰4ä½NormalFloatï¼ˆNF4ï¼‰ï¼Œä¸€ç§æ–°çš„æ•°æ®ç±»å‹ï¼Œç†è®ºä¸Šæ˜¯æ­£æ€åˆ†å¸ƒæƒé‡çš„æœ€ä½³ä¿¡æ¯ï¼Œï¼ˆbï¼‰åŒé‡é‡åŒ–ï¼Œé€šè¿‡é‡åŒ–é‡åŒ–å¸¸æ•°æ¥å‡å°‘å¹³å‡å†…å­˜å ç”¨ï¼Œï¼ˆcï¼‰åˆ†é¡µä¼˜åŒ–å™¨æ¥ç®¡ç†å†…å­˜æ³¢åŠ¨ã€‚ä½œè€…ä½¿ç”¨ QLORA å¯¹ 1,000 å¤šä¸ªæ¨¡å‹è¿›è¡Œå¾®è°ƒï¼Œæä¾›è·¨ 8 ä¸ªæŒ‡ä»¤æ•°æ®é›†ã€å¤šç§æ¨¡å‹ç±»å‹ï¼ˆLLaMAã€T5ï¼‰å’Œæ— æ³•é€šè¿‡å¸¸è§„å¾®è°ƒè¿è¡Œçš„æ¨¡å‹è§„æ¨¡ï¼ˆä¾‹å¦‚ 33B å’Œ65Bå‚æ•°æ¨¡å‹ï¼‰å¹¶ç»™å‡ºäº†è¯¦ç»†çš„æŒ‡ä»¤éµå¾ªå’ŒèŠå¤©è¡¨ç°åˆ†æã€‚ä½œè€…çš„ç»“æœè¡¨æ˜ï¼Œå³ä½¿ä½¿ç”¨æ¯”ä»¥å‰çš„ SoTA æ›´å°çš„æ¨¡å‹ï¼ŒQLoRA å¯¹å°å‹é«˜è´¨é‡æ•°æ®é›†çš„å¾®è°ƒä¹Ÿä¼šäº§ç”Ÿæœ€å…ˆè¿›çš„ç»“æœã€‚ä½œè€…æä¾›äº†ä¸€ä¸ªåŸºäºäººç±»å’ŒGPT-4è¯„ä¼°çš„èŠå¤©æœºå™¨äººæ€§èƒ½çš„è¯¦ç»†åˆ†æï¼Œè¡¨æ˜GPT-4è¯„ä¼°æ˜¯ä¸€ç§å»‰ä»·ä¸”åˆç†çš„æ›¿ä»£äººç±»è¯„ä¼°çš„æ–¹æ¡ˆã€‚æ­¤å¤–ï¼Œæˆ‘ä»¬å‘ç°å½“å‰çš„èŠå¤©æœºå™¨äººåŸºå‡†æµ‹è¯•ä¸èƒ½å‡†ç¡®è¯„ä¼°èŠå¤©æœºå™¨äººçš„æ€§èƒ½æ°´å¹³ã€‚æŸ æª¬æŒ‘é€‰åˆ†æå±•ç¤ºäº†Guanacoä¸ChatGPTç›¸æ¯”çš„å¤±è´¥ä¹‹å¤„ã€‚ä½œè€…å‘å¸ƒäº†æ‰€æœ‰çš„æ¨¡å‹å’Œä»£ç ï¼ŒåŒ…æ‹¬4ä½è®­ç»ƒçš„CUDAå†…æ ¸ã€‚\n",
    "```\n",
    "\n",
    "### **èµ„æº**\n",
    "\n",
    "è¿™ç¯‡åšæ–‡å’Œç‰ˆæœ¬é™„å¸¦äº†ä¸€äº›èµ„æºï¼Œå¯å¸®åŠ©æ‚¨å¼€å§‹ä½¿ç”¨ 4 ä½æ¨¡å‹å’Œ QLoRAï¼š\n",
    "\n",
    "- [åŸå§‹è®ºæ–‡](https://arxiv.org/abs/2305.14314)\n",
    "- [ä½¿ç”¨ Google Colab notebook](https://colab.research.google.com/drive/1ge2F1QSK8Q7h0hn3YKuBCOAS0bK8E0wf?usp=sharing)\n",
    "    \n",
    "    - è¯¥colab notebookå±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ 4 ä½æ¨¡å‹å¯¹å…¶æ‰€æœ‰å˜ä½“è¿›è¡Œæ¨ç†ï¼Œä»¥åŠå¦‚ä½•åœ¨å…è´¹çš„ Google Colab å®ä¾‹ä¸Šè¿è¡Œ GPT-neo-Xï¼ˆ20B å‚æ•°æ¨¡å‹ï¼‰ğŸ¤¯\n",
    "    \n",
    "- [å¾®è°ƒ Google Colab notebook](https://colab.research.google.com/drive/1VoYNfYDKcKRQRor98Zbf2-9VQTtGJ24k?usp=sharing)\n",
    "    - è¯¥**notebook**å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨ Hugging Face ç”Ÿæ€ç³»ç»Ÿåœ¨ä¸‹æ¸¸ä»»åŠ¡ä¸Šå¾®è°ƒ 4 ä½æ¨¡å‹ã€‚\n",
    "        \n",
    "        æˆ‘ä»¬è¯æ˜å¯ä»¥åœ¨ Google Colab å®ä¾‹ä¸Šå¾®è°ƒ GPT-neo-X 20Bï¼\n",
    "        \n",
    "- [è®ºæ–‡å¤ç°ä»“åº“](https://github.com/artidoro/qlora)\n",
    "- [Guanacoï¼ˆåŸé©¼ï¼‰ 33b playground](https://huggingface.co/spaces/uwnlp/guanaco-playground-tgi)\n",
    "\n",
    "### **ä»‹ç»**\n",
    "\n",
    "å¦‚æœä¸ç†Ÿæ‚‰æ¨¡å‹ç²¾åº¦å’Œæœ€å¸¸è§çš„æ•°æ®ç±»å‹ï¼ˆfloat16ã€float32ã€bfloat16ã€int8ï¼‰ï¼Œå»ºè®®é˜…è¯»æˆ‘ä»¬ç¬¬ä¸€ç¯‡[åšæ–‡](https://huggingface.co/blog/hf-bitsandbytes-integration)ä¸­çš„ä»‹ç»ã€‚æ›´å¤šä¿¡æ¯é˜…è¯» [wikibook](https://en.wikibooks.org/wiki/A-level_Computing/AQA/Paper_2/Fundamentals_of_data_representation/Floating_point_numbers#:~:text=In%20decimal%2C%20very%20large%20numbers,be%20used%20for%20binary%20numbers.) æ–‡æ¡£**ä¸­çš„æµ®ç‚¹è¡¨ç¤ºåŸºç¡€çŸ¥è¯†ã€‚\n",
    "\n",
    "æœ€è¿‘çš„ QLoRA è®ºæ–‡æ¢è®¨äº†ä¸åŒçš„æ•°æ®ç±»å‹ï¼Œ4 ä½ Float å’Œ 4 ä½ NormalFloatã€‚æˆ‘ä»¬å°†åœ¨è¿™é‡Œè®¨è®ºæ›´å®¹æ˜“ç†è§£ 4 ä½ Float æ•°æ®ç±»å‹ã€‚\n",
    "\n",
    "FP8 å’Œ FP4 åˆ†åˆ«ä»£è¡¨æµ®ç‚¹ 8 ä½å’Œ 4 ä½ç²¾åº¦ã€‚å®ƒä»¬æ˜¯æµ®ç‚¹å€¼ minifloats ç³»åˆ—çš„ä¸€éƒ¨åˆ†ï¼ˆé™¤å…¶ä»–ç²¾åº¦å¤–ï¼Œminifloats ç³»åˆ—è¿˜åŒ…æ‹¬ bfloat16 å’Œ float16ï¼‰ã€‚\n",
    "\n",
    "è®©æˆ‘ä»¬å…ˆçœ‹çœ‹å¦‚ä½•ç”¨ FP8 æ ¼å¼è¡¨ç¤ºæµ®ç‚¹å€¼ï¼Œç„¶åäº†è§£ FP4 æ ¼å¼çš„æ ·å­ã€‚\n",
    "\n",
    "### FP8 æ ¼å¼\n",
    "\n",
    "æ­£å¦‚æˆ‘ä»¬åœ¨ä¹‹å‰çš„åšæ–‡ä¸­æ‰€è®¨è®ºçš„ï¼Œä¸€ä¸ªæµ®ç‚¹æ•°åŒ…å« n ä½ï¼Œæ¯ä¸€ä½éƒ½å±äºä¸€ä¸ªç‰¹å®šçš„ç±»åˆ«ï¼Œè´Ÿè´£è¡¨ç¤ºæ•°å­—çš„ä¸€ä¸ªç»„æˆéƒ¨åˆ†ï¼ˆç¬¦å·ã€å°¾æ•°å’ŒæŒ‡æ•°ï¼‰ã€‚è¿™äº›ä»£è¡¨ä»¥ä¸‹å†…å®¹ã€‚\n",
    "\n",
    "FP8ï¼ˆfloating point 8ï¼‰æ ¼å¼åœ¨è®ºæ–‡**[â€œFP8 for Deep Learningâ€](https://arxiv.org/pdf/2209.05433.pdf)**ä¸­é¦–æ¬¡å¼•å…¥ï¼Œå…·æœ‰ä¸¤ç§ä¸åŒçš„ FP8 ç¼–ç ï¼šE4M3ï¼ˆ4 ä½æŒ‡æ•°å’Œ 3 ä½å°¾æ•°ï¼‰å’Œ E5M2ï¼ˆ5 ä½æŒ‡æ•°å’Œ 2 ä½å°¾æ•°ï¼‰ã€‚\n",
    "\n",
    "![[FP8-scheme.png](https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/blog/bitsandbytes/FP8-scheme.png)](FP8-scheme.png)\n",
    "\n",
    "\n",
    "**8ä½æµ®ç‚¹  (FP8) æ ¼å¼ï¼Œæ¥æºï¼šsgugger**\n",
    "\n",
    "\n",
    "\n",
    "ä» 32 ä½å‡å°‘åˆ° 8 ä½å¤§å¤§é™ä½äº†ç²¾åº¦ï¼Œå¯ä»¥æ ¹æ®ä¸åŒçš„éœ€è¦æ¥ä½¿ç”¨ä¸åŒç‰ˆæœ¬ã€‚ç›®å‰å¯ä»¥ä½¿ç”¨[Transformer Engine åº“](https://github.com/NVIDIA/TransformerEngine)ï¼Œè¯¥åº“å·²ç»ä¸ HF ç”Ÿæ€é›†æˆã€‚\n",
    "\n",
    "E4M3 æ ¼å¼è¡¨ç¤ºçš„æµ®ç‚¹æ•°åœ¨ -448 åˆ° 448 èŒƒå›´å†…ï¼Œè€Œåœ¨ E5M2 æ ¼å¼ä¸­ï¼Œéšç€æŒ‡æ•°ä½æ•°çš„å¢åŠ ï¼ŒèŒƒå›´å¢åŠ åˆ° -57344 åˆ° 57344 ï¼Œä½†æœ‰ç²¾åº¦æŸå¤±ï¼Œå› ä¸ºå¯è¡¨ç¤ºçš„æ€»ä½æ•°ä¿æŒä¸å˜ã€‚**ç»éªŒè¯æ˜ï¼ŒE4M3 æœ€é€‚åˆå‰å‘ä¼ æ’­ï¼Œè€Œ E5M2 æœ€é€‚åˆåå‘è®¡ç®—ã€‚**\n",
    "\n",
    "### **FP4 ç²¾åº¦ç®€è¿°**\n",
    "\n",
    "ç¬¦å·ä½è¡¨ç¤ºç¬¦å· (+/-)ï¼Œ~~æŒ‡æ•°ä½ä»¥ä¸¤ä½è¡¨ç¤ºçš„æ•´æ•°æ¬¡æ–¹ä¸ºåº•æ•°~~ æŒ‡æ•°ä½è¡¨ç¤ºä¸ºä»¥2ä¸ºåº•ï¼Œä½å½¢å¼çš„æ•´æ•°ä¸ºå¹‚ï¼ˆä¾‹å¦‚`2^{010} = 2^{2} = 4`ï¼‰ï¼Œå°¾æ•°æ˜¯ä»¥2ä¸ºåº•ã€ä½æ•°çš„è´Ÿå€¼ä¸ºå¹‚çš„å„ä½ä¹‹å’Œï¼Œä½æ•°åªå¯¹æ¯ä¸ªä¸ºâ€œ1â€çš„ä½â€œæœ‰æ•ˆâ€ã€‚å¦‚æœæŸä¸ªä½æ˜¯â€œ0â€ï¼Œåˆ™åˆ†æ•°ä¿æŒä¸å˜ï¼Œå¯¹äº`2^-i` ï¼Œi æ˜¯è¯¥ä½åœ¨ä½åºåˆ—ä¸­çš„ä½ç½®ã€‚ä¾‹å¦‚ï¼Œå¯¹äºå°¾æ•°ä½ 1010ï¼Œæˆ‘ä»¬æœ‰`(0 + 2^-1 + 0 + 2^-3) = (0.5 + 0.125) = 0.625`.Â ä¸ºäº†å¾—åˆ°ä¸€ä¸ªå€¼ï¼Œæˆ‘ä»¬å°†åˆ†æ•°åŠ *1*å¹¶å°†æ‰€æœ‰ç»“æœç›¸ä¹˜ï¼Œä¾‹å¦‚ï¼Œä½¿ç”¨ 2 ä¸ªæŒ‡æ•°ä½å’Œä¸€ä¸ªå°¾æ•°ä½ï¼Œè¡¨ç¤º 1101 å°†æ˜¯ï¼š`-1 * 2^(2) * (1 + 2^-1) = -1 * 4 * 1.5 = -6`\n",
    "\n",
    "å¯¹äº FP4 æ²¡æœ‰å›ºå®šçš„æ ¼å¼ï¼Œå› æ­¤å¯ä»¥å°è¯•ä¸åŒå°¾æ•°/æŒ‡æ•°çš„ç»„åˆã€‚é€šå¸¸ï¼Œåœ¨å¤§å¤šæ•°æƒ…å†µä¸‹ï¼Œ3 ä¸ªæŒ‡æ•°ä½ä¼šå¥½ä¸€äº›ã€‚ä½†æœ‰æ—¶ 2 ä¸ªæŒ‡æ•°ä½å’Œä¸€ä¸ªå°¾æ•°ä½ä¼šäº§ç”Ÿæ›´å¥½çš„æ€§èƒ½ã€‚\n",
    "\n",
    "### **QLoRA è®ºæ–‡ï¼šä¸€ç§æ–°å‹é‡åŒ– Transformer å¤§æ¨¡å‹çš„äº²æ°‘æ–¹æ³•**\n",
    "\n",
    "ç®€è€Œè¨€ä¹‹ï¼Œä¸ 16 ä½æ¨¡å‹å¾®è°ƒç›¸æ¯”ï¼ŒQLoRA åœ¨ä¸ç‰ºç‰²æ€§èƒ½æƒ…å†µä¸‹å‡å°‘äº† LLM å¾®è°ƒçš„å†…å­˜ä½¿ç”¨ã€‚è¯¥æ–¹æ³•åœ¨å•ä¸ª 24GB GPU ä¸Šå®ç° 33B æ¨¡å‹å¾®è°ƒï¼Œåœ¨å•ä¸ª 46GB GPU ä¸Šå®ç° 65B æ¨¡å‹å¾®è°ƒã€‚\n",
    "\n",
    "æ›´å…·ä½“åœ°è¯´ï¼Œ**QLoRA ä½¿ç”¨ 4 ä½é‡åŒ–æ¥å‹ç¼©é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹**ã€‚ç„¶åå†»ç»“ LM å‚æ•°ï¼Œå¹¶å°†ç›¸å¯¹å°‘é‡çš„å¯è®­ç»ƒå‚æ•°ä»¥ä½é˜¶é€‚é…å™¨çš„å½¢å¼æ·»åŠ åˆ°æ¨¡å‹ä¸­ã€‚åœ¨å¾®è°ƒæœŸé—´ï¼ŒQLoRA é€šè¿‡å†»ç»“çš„ 4 ä½é‡åŒ–é¢„è®­ç»ƒè¯­è¨€æ¨¡å‹å°†æ¢¯åº¦åå‘ä¼ æ’­åˆ°ä½é˜¶é€‚é…å™¨ã€‚LoRA å±‚æ˜¯è®­ç»ƒæœŸé—´å”¯ä¸€æ›´æ–°çš„å‚æ•°ã€‚**[åœ¨åŸå§‹çš„ LoRA è®ºæ–‡](https://arxiv.org/abs/2106.09685)**ä¸­é˜…è¯»æœ‰å…³ LoRA çš„æ›´å¤šä¿¡æ¯ã€‚\n",
    "\n",
    "QLoRA åŒ…å«å­˜å‚¨æ•°æ®ç±»å‹ï¼ˆé€šå¸¸æ˜¯ 4 ä½ NormalFloatï¼‰å’Œè®¡ç®—æ•°æ®ç±»å‹ï¼ˆ16 ä½ BrainFloatï¼‰ã€‚QLoRA å°†å­˜å‚¨æ•°æ®ç±»å‹çš„æƒé‡åé‡åŒ–ä¸ºè®¡ç®—æ•°æ®ç±»å‹ä»¥æ‰§è¡Œå‰å‘å’Œåå‘ä¼ é€’ï¼Œä½†ä»…è®¡ç®—ä½¿ç”¨ 16 ä½ bfloat çš„ LoRA å‚æ•°çš„æƒé‡æ¢¯åº¦ã€‚æƒé‡ä»…åœ¨éœ€è¦æ—¶è§£å‹ç¼©ï¼Œå› æ­¤åœ¨è®­ç»ƒå’Œæ¨ç†æœŸé—´å†…å­˜ä½¿ç”¨ç‡ä¿æŒè¾ƒä½ã€‚\n",
    "\n",
    "åœ¨å¹¿æ³›çš„å®éªŒä¸­ï¼ŒQLoRA å¾®è°ƒä¸ 16 ä½å¾®è°ƒæ–¹æ³•æ•ˆæœç›¸å½“ã€‚æ­¤å¤–ï¼Œåœ¨**[OpenAssistant æ•°æ®é›† (OASST1)](https://huggingface.co/datasets/OpenAssistant/oasst1)**ä¸Šå¯¹ LLaMA æ¨¡å‹ä½¿ç”¨ QLoRA å¾®è°ƒå¾—åˆ° Guanaco æ¨¡å‹ï¼ŒåŸºäºè¯¥æ¨¡å‹çš„èŠå¤©è¡¨ç°è¾¾åˆ°SOTAè¡¨ç°ï¼Œåœ¨ Vicuna åŸºå‡†æµ‹è¯•ä¸Šæ¥è¿‘ ChatGPTï¼Œè¿™å¤šå°‘æœ‰ç‚¹è¶…å‡ºå¯¹QLoRA å¾®è°ƒçš„é¢„æœŸã€‚\n",
    "\n",
    "æ›´è¯¦ç»†çš„ä¿¡æ¯è¯·é˜…è¯»**[QLoRA è®ºæ–‡](https://arxiv.org/abs/2305.14314)**ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "\n",
    "nf4_config = BitsAndBytesConfig(\n",
    "   load_in_4bit=True,\n",
    "   bnb_4bit_quant_type=\"nf4\",\n",
    "   bnb_4bit_use_double_quant=True,\n",
    "   bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "model_nf4 = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=nf4_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **æ›´æ”¹è®¡ç®—æ•°æ®ç±»å‹**\n",
    "\n",
    "å¦‚ä¸Šæ‰€è¿°ï¼Œæ‚¨è¿˜å¯ä»¥é€šè¿‡æ›´æ”¹`BitsAndBytesConfig`ä¸­çš„`bnb_4bit_compute_dtype`å‚æ•°æ¥æ›´æ”¹é‡åŒ–æ¨¡å‹çš„è®¡ç®—æ•°æ®ç±»å‹ã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BitsAndBytesConfig\n",
    "quantization_config = BitsAndBytesConfig(\n",
    "   load_in_4bit=True,\n",
    "   bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **åµŒå¥—é‡åŒ–**\n",
    "\n",
    "è¦å¯ç”¨åµŒå¥—é‡åŒ–ï¼Œæ‚¨å¯ä»¥ä½¿ç”¨`BitsAndBytesConfig`ä¸­çš„`bnb_4bit_use_double_quant`å‚æ•°ã€‚è¿™å°†åœ¨ç¬¬ä¸€æ¬¡é‡åŒ–ä¹‹åå¯ç”¨ç¬¬äºŒæ¬¡é‡åŒ–ï¼Œä»¥ä¾¿ä¸ºæ¯ä¸ªå‚æ•°é¢å¤–èŠ‚çœ 0.4 ä½ã€‚æˆ‘ä»¬ä¹Ÿåœ¨è®­ç»ƒ Google colab notebook ä¸­ä½¿ç”¨äº†è¿™ä¸ªç‰¹æ€§\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "double_quant_config = BitsAndBytesConfig(\n",
    "   load_in_4bit=True,\n",
    "   bnb_4bit_use_double_quant=True)\n",
    "model_double_quant = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=double_quant_config)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "å½“ç„¶ï¼Œæ‰€æœ‰è¿™äº›ç»„ä»¶éƒ½æ˜¯å¯ç»„åˆçš„ã€‚æ‚¨å¯ä»¥å°†æ‰€æœ‰å‚æ•°ç»„åˆä»¥æ‰¾åˆ°æœ€é€‚åˆçš„ç”¨ä¾‹ã€‚ä¸€æ¡ç»éªŒæ³•åˆ™æ˜¯ï¼šå¦‚æœå†…å­˜æœ‰é—®é¢˜ï¼Œè¯·ä½¿ç”¨åŒé‡åŒ–ï¼Œä½¿ç”¨ NF4 ä»¥è·å¾—æ›´é«˜çš„ç²¾åº¦ï¼Œä½¿ç”¨ 16 ä½ dtype æ¥å®ç°æ›´å¿«çš„å¾®è°ƒã€‚ä¾‹å¦‚ï¼Œåœ¨**[æ¨ç†æ¼”ç¤º](https://colab.research.google.com/drive/1ge2F1QSK8Q7h0hn3YKuBCOAS0bK8E0wf?usp=sharing)**ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨åµŒå¥—é‡åŒ–ã€bfloat16 è®¡ç®— dtype å’Œ NF4 é‡åŒ–åœ¨å•ä¸ª 16GB GPU ä¸­ä»¥ 4 ä½å®Œå…¨å¾®è°ƒ gpt-neo-x-20b (40GB)ã€‚\n",
    "\n",
    "### **å¸¸è§é—®é¢˜**\n",
    "\n",
    "åœ¨æœ¬èŠ‚ä¸­ï¼Œæˆ‘ä»¬è¿˜å°†è§£å†³ä»»ä½•äººå¯èƒ½å¯¹æ­¤é›†æˆæå‡ºçš„ä¸€äº›å¸¸è§é—®é¢˜ã€‚\n",
    "\n",
    "**FP4é‡åŒ–æœ‰ç¡¬ä»¶è¦æ±‚å—ï¼Ÿ**\n",
    "\n",
    "è¯·æ³¨æ„ï¼Œæ­¤æ–¹æ³•ä»…ä¸ GPU å…¼å®¹ï¼Œå› æ­¤æ— æ³•åœ¨ CPU ä¸Šä»¥ 4 ä½é‡åŒ–æ¨¡å‹ã€‚ åœ¨ GPU ä¸­ï¼Œè¿™ç§æ–¹æ³•åº”è¯¥æ²¡æœ‰ä»»ä½•ç¡¬ä»¶è¦æ±‚ï¼Œå› æ­¤åªè¦å®‰è£…äº† CUDA>=11.2ï¼Œä»»ä½• GPU éƒ½å¯ä»¥ç”¨äºè¿è¡Œ 4bit é‡åŒ–ã€‚ æ³¨æ„ï¼Œè®¡ç®—ä¸æ˜¯åœ¨ 4 ä½ä¸­å®Œæˆï¼Œåªæ˜¯æƒé‡å’Œæ¿€æ´»è¢«å‹ç¼©ä¸ºè¯¥æ ¼å¼ï¼Œè®¡ç®—ä»ç„¶ä¿æŒä¸ºæœŸæœ›çš„ dtypeç±»å‹ã€‚\n",
    "\n",
    "### **æ”¯æŒçš„æ¨¡å‹æœ‰å“ªäº›ï¼Ÿ**\n",
    "\n",
    "**[ä¸æœ¬åšæ–‡](https://huggingface.co/blog/hf-bitsandbytes-integration)**ä¸­ä»‹ç»çš„ LLM.int8 é›†æˆç±»ä¼¼ï¼Œæ”¯æŒé›†æˆå¾ˆå¤§ç¨‹åº¦ä¸Šä¾èµ–äº`accelerate`åº“ã€‚å› æ­¤ï¼Œä»»ä½•æ”¯æŒåŠ é€ŸåŠ è½½çš„æ¨¡å‹ï¼ˆå³`from_pretrained`è°ƒç”¨`çš„device_map`å‚æ•°ï¼‰éƒ½åº”è¯¥æ˜¯4bitå¯é‡åŒ–çš„ã€‚å¦è¯·æ³¨æ„ï¼Œè¿™ä¸æ¨¡æ€å®Œå…¨æ— å…³ï¼Œåªè¦æ¨¡å‹å¯ä»¥åŠ è½½å‚æ•°`device_map`ï¼Œå°±å¯ä»¥é‡åŒ–å®ƒä»¬ã€‚\n",
    "\n",
    "å¯¹äºç”Ÿæˆå¼æ¨¡å‹ï¼Œæ”¯æŒåŒ…æ‹¬æœ€å¸¸ç”¨çš„æ–‡æœ¬æ¶æ„ï¼Œä¾‹å¦‚ Llamaã€OPTã€GPT-Neoã€GPT-NeoXã€ç”¨äºå¤šæ¨¡æ€æ¨¡å‹çš„ Blip2 ç­‰ã€‚\n",
    "\n",
    "æˆªæ­¢æœ¬åšå®¢æ’°å†™ï¼Œæ”¯æŒåŠ é€Ÿçš„æ¨¡å‹æœ‰ï¼š\n",
    "\n",
    "```\n",
    "[\n",
    "    'bigbird_pegasus', 'blip_2', 'bloom', 'bridgetower', 'codegen', 'deit', 'esm',\n",
    "    'gpt2', 'gpt_bigcode', 'gpt_neo', 'gpt_neox', 'gpt_neox_japanese', 'gptj', 'gptsan_japanese',\n",
    "    'lilt', 'llama', 'longformer', 'longt5', 'luke', 'm2m_100', 'mbart', 'mega', 'mt5', 'nllb_moe',\n",
    "    'open_llama', 'opt', 'owlvit', 'plbart', 'roberta', 'roberta_prelayernorm', 'rwkv', 'switch_transformers',\n",
    "    't5', 'vilt', 'vit', 'vit_hybrid', 'whisper', 'xglm', 'xlm_roberta'\n",
    "]\n",
    "\n",
    "```\n",
    "\n",
    "è¯·æ³¨æ„ï¼Œå¦‚æœæ‚¨æƒ³è¦çš„æ¨¡å‹ä¸åœ¨è¿™é‡Œï¼Œæ‚¨å¯ä»¥å¼€ä¸€ä¸ªPull Requestæˆ–åœ¨transformers ä¸­æå‡ºä¸€ä¸ªissueï¼Œå¯ä»¥åŠ å¿«è¯¥æ¶æ„å¯¹æ¨¡å‹çš„æ”¯æŒã€‚\n",
    "\n",
    "### **å¯ä»¥è®­ç»ƒ 4 ä½/8 ä½æ¨¡å‹å—ï¼Ÿ**\n",
    "\n",
    "ä¸å¯ä»¥åœ¨è¿™äº›æ¨¡å‹ä¸Šæ‰§è¡Œçº¯ 4 ä½è®­ç»ƒã€‚ä½†æ˜¯ï¼Œæ‚¨å¯ä»¥é€šè¿‡åˆ©ç”¨å‚æ•°é«˜æ•ˆå¾®è°ƒæ–¹æ³• (PEFT) æ¥è®­ç»ƒè¿™äº›æ¨¡å‹ï¼Œå¹¶åœ¨å®ƒä»¬ä¹‹ä¸Šè®­ç»ƒä¾‹å¦‚é€‚é…å™¨ã€‚è¿™å°±æ˜¯è®ºæ–‡ä¸­æ‰€åšçš„ï¼Œå¹¶å¾—åˆ° Hugging Face çš„ PEFT åº“çš„æ­£å¼æ”¯æŒã€‚æˆ‘ä»¬è¿˜æä¾›äº†ä¸€ä¸ª[è®­ç»ƒnotebook](https://colab.research.google.com/drive/1VoYNfYDKcKRQRor98Zbf2-9VQTtGJ24k?usp=sharing)**ï¼Œå¦‚æœç”¨æˆ·æœ‰å…´è¶£å¤åˆ¶è®ºæ–‡ä¸­çš„ç»“æœï¼Œå»ºè®®ä»–ä»¬æŸ¥çœ‹[QLoRA å­˜å‚¨åº“ã€‚](https://github.com/artidoro/qlora)\n",
    "\n",
    "![[lora-animated.gif](https://huggingface.co/datasets/trl-internal-testing/example-images/resolve/main/blog/133_trl_peft/lora-animated.gif)](lora-animated.gif)\n",
    "\n",
    "**åŸå§‹ï¼ˆå†»ç»“çš„ï¼‰é¢„è®­ç»ƒæƒé‡ï¼ˆå·¦ï¼‰ã€æƒé‡çŸ©é˜µ A å’Œ B ç»„æˆçš„ä½ç§©é€‚é…å™¨ï¼ˆå³ï¼‰ã€å…±åŒå¢å¼ºåŸå§‹æ¿€æ´»hã€‚**\n",
    "\n",
    "\n",
    "### å…¶ä»–å½±å“\n",
    "\n",
    "è¿™ç§é›†æˆå¯ä»¥ä¸ºç¤¾åŒºå’Œ AI ç ”ç©¶å¸¦æ¥ä¸€äº›ç§¯æçš„å½±å“ï¼Œå› ä¸ºå®ƒå¯ä»¥å½±å“å¤šä¸ªæ¨¡å‹å’Œå¯èƒ½çš„åº”ç”¨ç¨‹åºã€‚åœ¨ RLHFï¼ˆäººç±»åé¦ˆå¼ºåŒ–å­¦ä¹ ï¼‰ä¸­ï¼Œå¯ä»¥åŠ è½½ä¸€ä¸ª 4 ä½åŸºç¡€æ¨¡å‹å¹¶åœ¨å…¶ä¸Šè®­ç»ƒå¤šä¸ªé€‚é…å™¨ï¼Œä¸€ä¸ªç”¨äºå¥–åŠ±å»ºæ¨¡ï¼Œå¦ä¸€ä¸ªç”¨äºä»·å€¼ç­–ç•¥è®­ç»ƒã€‚å…³äºæ­¤ç”¨ä¾‹çš„æ›´è¯¦ç»†çš„åšæ–‡å’Œå…¬å‘Šå°†å¾ˆå¿«å‘å¸ƒã€‚\n",
    "\n",
    "æˆ‘ä»¬è¿˜é’ˆå¯¹è¿™ç§é‡åŒ–æ–¹æ³•å¯¹åœ¨æ¶ˆè´¹ç±»ç¡¬ä»¶ä¸Šè®­ç»ƒå¤§å‹æ¨¡å‹çš„å½±å“åšäº†ä¸€äº›åŸºå‡†æµ‹è¯•ã€‚æˆ‘ä»¬åœ¨ NVIDIA T4 (16GB) ä¸Šè¿è¡Œäº†å‡ ä¸ªå¾®è°ƒ 2 ç§ä¸åŒæ¶æ„çš„å®éªŒï¼ŒLlama 7Bï¼ˆfp16ä¸‹ 15GBï¼‰å’Œ Llama 13Bï¼ˆfp16 ä¸‹ 27GBï¼‰ï¼Œè¿™æ˜¯ç»“æœ\n",
    "\n",
    "\n",
    "| Model name | Half precision model size (in GB) | Hardware type / total VRAM | quantization method (CD=compute dtype / GC=gradient checkpointing / NQ=nested quantization) | batch_size | gradient accumulation steps | optimizer | seq_len | Result |\n",
    "| --- | --- | --- | --- | --- | --- | --- | --- | --- |\n",
    "| <10B scale models |  |  |  |  |  |  |  |  |\n",
    "| decapoda-research/llama-7b-hf | 14GB | 1xNVIDIA-T4 / 16GB | LLM.int8 (8-bit) + GC | 1 | 4 | AdamW | 512 | No OOM |\n",
    "| decapoda-research/llama-7b-hf | 14GB | 1xNVIDIA-T4 / 16GB | LLM.int8 (8-bit) + GC | 1 | 4 | AdamW | 1024 | OOM |\n",
    "| decapoda-research/llama-7b-hf | 14GB | 1xNVIDIA-T4 / 16GB | 4bit + NF4 + bf16 CD + no GC | 1 | 4 | AdamW | 512 | No OOM |\n",
    "| decapoda-research/llama-7b-hf | 14GB | 1xNVIDIA-T4 / 16GB | 4bit + FP4 + bf16 CD + no GC | 1 | 4 | AdamW | 512 | No OOM |\n",
    "| decapoda-research/llama-7b-hf | 14GB | 1xNVIDIA-T4 / 16GB | 4bit + NF4 + bf16 CD + no GC | 1 | 4 | AdamW | 1024 | OOM |\n",
    "| decapoda-research/llama-7b-hf | 14GB | 1xNVIDIA-T4 / 16GB | 4bit + FP4 + bf16 CD + no GC | 1 | 4 | AdamW | 1024 | OOM |\n",
    "| decapoda-research/llama-7b-hf | 14GB | 1xNVIDIA-T4 / 16GB | 4bit + NF4 + bf16 CD + GC | 1 | 4 | AdamW | 1024 | No OOM |\n",
    "| 10B+ scale models |  |  |  |  |  |  |  |  |\n",
    "| decapoda-research/llama-13b-hf | 27GB | 2xNVIDIA-T4 / 32GB | LLM.int8 (8-bit) + GC | 1 | 4 | AdamW | 512 | No OOM |\n",
    "| decapoda-research/llama-13b-hf | 27GB | 1xNVIDIA-T4 / 16GB | LLM.int8 (8-bit) + GC | 1 | 4 | AdamW | 512 | OOM |\n",
    "| decapoda-research/llama-13b-hf | 27GB | 1xNVIDIA-T4 / 16GB | 4bit + FP4 + bf16 CD + no GC | 1 | 4 | AdamW | 512 | OOM |\n",
    "| decapoda-research/llama-13b-hf | 27GB | 1xNVIDIA-T4 / 16GB | 4bit + FP4 + fp16 CD + no GC | 1 | 4 | AdamW | 512 | OOM |\n",
    "| decapoda-research/llama-13b-hf | 27GB | 1xNVIDIA-T4 / 16GB | 4bit + NF4 + fp16 CD + GC | 1 | 4 | AdamW | 512 | No OOM |\n",
    "| decapoda-research/llama-13b-hf | 27GB | 1xNVIDIA-T4 / 16GB | 4bit + NF4 + fp16 CD + GC | 1 | 4 | AdamW | 1024 | OOM |\n",
    "| decapoda-research/llama-13b-hf | 27GB | 1xNVIDIA-T4 / 16GB | 4bit + NF4 + fp16 CD + GC + NQ | 1 | 4 | AdamW | 1024 | No OOM |\n",
    "\n",
    "\n",
    "æˆ‘ä»¬ä½¿ç”¨äº†æœ€è¿‘çš„TRL åº“ï¼ŒåŸºå‡†æµ‹è¯•è„šæœ¬å¯ä»¥**[åœ¨è¿™é‡Œ](https://gist.github.com/younesbelkada/f48af54c74ba6a39a7ae4fd777e72fe8)**`SFTTrainer`æ‰¾åˆ°\n",
    "\n",
    "### **Playground**\n",
    "\n",
    "[Playground](https://huggingface.co/spaces/uwnlp/guanaco-playground-tgi)ä¸Šä½“éªŒ Guananco æ¨¡å‹\n",
    "\n",
    "### **è‡´è°¢**\n",
    "\n",
    "HF å›¢é˜Ÿè¦æ„Ÿè°¢åç››é¡¿å¤§å­¦æ‰€æœ‰å‚ä¸è¯¥é¡¹ç›®çš„äººå‘˜ï¼Œæ„Ÿè°¢ä»–ä»¬å°†æ­¤é¡¹ç›®æä¾›ç»™ç¤¾åŒºã€‚\n",
    "\n",
    "è¿˜è¦æ„Ÿè°¢**[Pedro Cuenca](https://huggingface.co/pcuenq)**å¯¹åšæ–‡çš„å‹å¥½å®¡é˜…ï¼Œæ„Ÿè°¢**[Olivier Dehaene](https://huggingface.co/olivierdehaene)**å’Œ**[Omar Sanseviero](https://huggingface.co/osanseviero)**å¯¹ HF Hub ä¸Šè®ºæ–‡å·¥ä»¶é›†æˆçš„å¿«é€Ÿå’Œå¤§åŠ›æ”¯æŒã€‚"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> è‹±æ–‡åŸæ–‡: <url> https://huggingface.co/blog/4bit-transformers-bitsandbytes </url>\n",
    "\n",
    "> åŸæ–‡ä½œè€…ï¼šYounes Belkadaç­‰\n",
    "\n",
    "> è¯‘è€…: Cony Zhang (å¼ èªèª)ï¼ŒNLPç®—æ³•å·¥ç¨‹å¸ˆï¼Œå·¥ä½œæ–¹å‘ä¸º LLMç ”ç©¶ä¸è½åœ°ã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d58e898dde0263bc564c6968b04150abacfd33eed9b19aaa8e45c040360e146"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
