{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ä½¿ç”¨ DeepSpeed å’Œ Hugging Face ğŸ¤— Transformer å¾®è°ƒ FLAN-T5 XL/XXL\n",
    "\n",
    "è¯‘è€…: Matrix Yao (å§šä¼Ÿå³°)\n",
    "\n",
    "[Scaling Instruction-Finetuned Language Models](https://arxiv.org/pdf/2210.11416.pdf) è®ºæ–‡å‘å¸ƒäº† FLAN-T5 æ¨¡å‹ï¼Œå®ƒæ˜¯ T5 æ¨¡å‹çš„å¢å¼ºç‰ˆã€‚FLAN-T5 ç”±å¾ˆå¤šå„ç§å„æ ·çš„ä»»åŠ¡å¾®è°ƒè€Œå¾—ï¼Œå› æ­¤ï¼Œç®€å•æ¥è®²ï¼Œå®ƒå°±æ˜¯ä¸ªæ–¹æ–¹é¢é¢éƒ½æ›´ä¼˜çš„ T5 æ¨¡å‹ã€‚ç›¸åŒå‚æ•°é‡çš„æ¡ä»¶ä¸‹ï¼ŒFLAN-T5 çš„æ€§èƒ½ç›¸æ¯” T5 è€Œè¨€æœ‰ä¸¤ä½æ•°çš„æé«˜ã€‚Google åœ¨ Hugging Face ä¸Šå¼€æºäº† [5 ä¸ª FLAN-T5 çš„ checkpoints](https://huggingface.co/models?other=arxiv:2210.11416)ï¼Œå‚æ•°é‡èŒƒå›´ä» 8000 ä¸‡  åˆ° 110 äº¿ã€‚\n",
    "\n",
    "åœ¨ä¹‹å‰çš„ä¸€ç¯‡åšæ–‡ä¸­ï¼Œæˆ‘ä»¬å·²ç»å­¦ä¹ äº†å¦‚ä½• [é’ˆå¯¹èŠå¤©å¯¹è¯æ•°æ®æ‘˜è¦ç”Ÿæˆä»»åŠ¡å¾®è°ƒ FLAN-T5](https://www.philschmid.de/fine-tune-flan-t5)ï¼Œé‚£æ—¶æˆ‘ä»¬ä½¿ç”¨çš„æ˜¯ [Base (250M å‚æ•°)](https://huggingface.co/google/flan-t5-base) æ¨¡å‹ã€‚æœ¬æ–‡ï¼Œæˆ‘ä»¬å°†ç ”ç©¶å¦‚ä½•å°†è®­ç»ƒä» Base æ‰©å±•åˆ° [XL (30 äº¿å‚æ•°)](https://huggingface.co/google/flan-t5-xl) æˆ– [XXL (110 äº¿å‚æ•°)](https://huggingface.co/google/flan-t5-xxl)ã€‚\n",
    "\n",
    "è¿™æ„å‘³ç€æˆ‘ä»¬å°†å­¦ä¹ å¦‚ä½•åˆ©ç”¨æ¨¡å‹å¹¶è¡Œã€å¤š GPU ä»¥åŠ [DeepSpeed ZeRO](https://www.deepspeed.ai/tutorials/zero/) æ¥å¾®è°ƒ FLAN-T5 XL å’Œ XXLã€‚\n",
    "\n",
    "é™¤äº†ä½œä¸ºæ•™ç¨‹çš„éƒ¨åˆ†ä¹‹å¤–ï¼Œæˆ‘ä»¬è¿˜è·‘äº†ä¸€ç³»åˆ—å®éªŒï¼Œè¿™äº›å®éªŒæ•°æ®å¯ä»¥å¸®åŠ©ä½ é€‰æ‹©æ­£ç¡®çš„ç¡¬ä»¶è®¾ç½®ã€‚ä½ å¯ä»¥åœ¨ **ç»“æœå’Œå®éªŒ** éƒ¨åˆ†æ‰¾åˆ°è¯¦ç»†ä¿¡æ¯ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install git lfs for pushing artifacts\n",
    "!sudo apt install git-lfs\n",
    "# install torch with the correct cuda version, check nvcc --version\n",
    "!pip install torch --extra-index-url https://download.pytorch.org/whl/cu116 --upgrade\n",
    "# install Hugging Face Libraries\n",
    "!pip install \"transformers==4.26.0\" \"datasets==2.9.0\" \"accelerate==0.16.0\" \"evaluate==0.4.0\" --upgrade\n",
    "# install deepspeed and ninja for jit compilations of kernels\n",
    "!pip install \"deepspeed==0.8.0\" ninja --upgrade\n",
    "# install additional dependencies needed for training\n",
    "!pip install rouge-score nltk py7zr tensorboard"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# å¤„ç†æ•°æ®é›†"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸ [é’ˆå¯¹èŠå¤©å¯¹è¯çš„æ‘˜è¦ç”Ÿæˆä»»åŠ¡å¾®è°ƒ FLAN-T5](https://www.philschmid.de/fine-tune-flan-t5) ä¸€æ–‡ä¸­ç±»ä¼¼ï¼Œæˆ‘ä»¬éœ€è¦å…ˆå‡†å¤‡ä¸€ä¸ªç”¨äºå¾®è°ƒçš„æ•°æ®é›†ã€‚æœ¬æ–‡ï¼Œæˆ‘ä»¬å°†åœ¨ [CNN Dailymail æ•°æ®é›†](https://huggingface.co/datasets/cnn_dailymail) ä¸Šå¾®è°ƒ [FLAN-T5-XXL](https://huggingface.co/google/flan-t5-xxl)ã€‚æˆ‘ä»¬ä¸ä¼šèµ˜è¿°å¦‚ä½•ç”Ÿæˆæ•°æ®é›†ï¼Œå¦‚æœä½ æƒ³äº†è§£æ•°æ®é›†ç”Ÿæˆçš„è¯¦ç»†æ­¥éª¤ï¼Œè¯·å‚é˜…å‰æ–‡æåˆ°çš„ [Fine Tune FLAN-T5](https://www.philschmid.de/fine-tune-flan-t5)ã€‚\n",
    "\n",
    "æˆ‘ä»¬å®šä¹‰äº†ä¸€äº›å‚æ•°ï¼Œæœ¬æ–‡çš„ç¤ºä¾‹éƒ½ä¼šåŸºäºè¿™äº›å‚æ•°ï¼Œä½†ä½ å¯ä»¥æ ¹æ®å®é™…éœ€è¦è¿›è¡Œè°ƒæ•´ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®éªŒæ€§çš„é…ç½®\n",
    "model_id = \"google/flan-t5-xxl\" # Hugging Face æ¨¡å‹ Id\n",
    "dataset_id = \"cnn_dailymail\" # Hugging Face æ•°æ®é›† Id\n",
    "dataset_config = \"3.0.0\" # æ•°æ®é›†ç‰ˆæœ¬\n",
    "save_dataset_path = \"data\" # å­˜æ”¾å¤„ç†åæ•°æ®çš„æœ¬åœ°è·¯å¾„\n",
    "text_column = \"article\" # è¾“å…¥æ–‡æœ¬æ‰€å±åˆ—\n",
    "summary_column = \"highlights\" # è¾“å‡ºæ–‡æœ¬æ‰€å±åˆ—\n",
    "# å®šåˆ¶æŒ‡ä»¤æç¤ºæ ¼å¼\n",
    "prompt_template = f\"Summarize the following news article:\\n{{input}}\\nSummary:\\n\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸ [Fine Tune FLAN-T5](https://www.philschmid.de/fine-tune-flan-t5) ä¸åŒï¼Œè¿™æ¬¡æˆ‘ä»¬æŠŠé¢„å¤„ç†å’Œè®­ç»ƒåˆ†å¼€ã€‚è¿™æ ·æˆ‘ä»¬å°±å¯ä»¥åœ¨é GPU å®ä¾‹ä¸Šè¿è¡Œé¢„å¤„ç†ã€‚æˆ‘ä»¬å…ˆå¯¹æ•°æ®é›†è¿›è¡Œé¢„å¤„ç† (å³åˆ†è¯) å¹¶å°†å…¶ä¿å­˜åˆ°ç£ç›˜ï¼Œç„¶åè®­ç»ƒè„šæœ¬å†ä»ç£ç›˜ä¸­åŠ è½½é¢„å¤„ç†åçš„æ•°æ®é›†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np \n",
    "\n",
    "# Load dataset from the hub\n",
    "dataset = load_dataset(dataset_id,name=dataset_config)\n",
    "# Load tokenizer of FLAN-t5-base\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "print(f\"Train dataset size: {len(dataset['train'])}\")\n",
    "print(f\"Test dataset size: {len(dataset['test'])}\")\n",
    "\n",
    "# Train dataset size: 287113\n",
    "# Test dataset size: 11490"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬åœ¨é…ç½®æ–‡ä»¶ä¸­å®šä¹‰äº†ä¸€ä¸ª `prompt_template`ï¼Œå…¶å¯ç”¨äºæ¥æ„å»ºæŒ‡ä»¤æç¤ºï¼Œä»¥æé«˜æˆ‘ä»¬æ¨¡å‹çš„æ€§èƒ½ã€‚ `prompt_template` æœ‰â€œå›ºå®šâ€çš„å¼€å§‹è¯å’Œç»“æŸè¯ï¼Œæ–‡æ¡£æ”¾åœ¨ä¸­é—´ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬éœ€è¦ç¡®ä¿ **â€œå›ºå®šâ€æ¨¡æ¿è¯ + æ–‡æ¡£** æ€»é•¿ä¸è¶…è¿‡æ¨¡å‹æ”¯æŒçš„æœ€å¤§åºåˆ—é•¿åº¦ã€‚å› æ­¤æˆ‘ä»¬éœ€è¦è®¡ç®—æ¨¡å‹æ”¯æŒçš„æœ€å¤§æ–‡æ¡£é•¿åº¦ï¼Œç¨åæˆ‘ä»¬ä¼šæ ¹æ®å®ƒæ¥å¡«å……æˆ–æˆªæ–­æ¨¡æ¿ä¸­çš„æ–‡æ¡£ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt length: 12\n",
      "Max input length: 500\n"
     ]
    }
   ],
   "source": [
    "prompt_length = len(tokenizer(prompt_template.format(input=\"\"))[\"input_ids\"])\n",
    "max_sample_length = tokenizer.model_max_length - prompt_length\n",
    "print(f\"Prompt length: {prompt_length}\")\n",
    "print(f\"Max input length: {max_sample_length}\")\n",
    "\n",
    "# Prompt length: 12\n",
    "# Max input length: 500"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç°åœ¨æˆ‘ä»¬çŸ¥é“ï¼Œæ¨¡å‹æ”¯æŒçš„æœ€å¤§è¾“å…¥æ–‡æ¡£é•¿åº¦ä¸º 500ã€‚é™¤äº†è¾“å…¥ä¹‹å¤–ï¼Œæˆ‘ä»¬è¿˜éœ€è¦çŸ¥é“æœ€å¤§â€œç›®æ ‡â€åºåˆ—é•¿åº¦ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡éå†æ•°æ®é›†ä¸­çš„æ‘˜è¦é•¿åº¦æ¥å¾—åˆ°ã€‚(ä»£ç éœ€è¦è¿è¡Œå‡ åˆ†é’Ÿ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.012465238571166992,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 299,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32577879b38640f898e798ea8f88a801",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/299 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max source length: 500\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.011892318725585938,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "",
       "rate": null,
       "total": 299,
       "unit": "ba",
       "unit_divisor": 1000,
       "unit_scale": false
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "724cc7afe0ba49a3b8a6a763a189e380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/299 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max target length: 129\n"
     ]
    }
   ],
   "source": [
    "from datasets import concatenate_datasets\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# The maximum total input sequence length after tokenization. \n",
    "# Sequences longer than this will be truncated, sequences shorter will be padded.\n",
    "tokenized_inputs = concatenate_datasets([dataset[\"train\"], dataset[\"test\"]]).map(lambda x: tokenizer(x[text_column], truncation=True), batched=True, remove_columns=[text_column, summary_column])\n",
    "max_source_length = max([len(x) for x in tokenized_inputs[\"input_ids\"]])\n",
    "max_source_length = min(max_source_length, max_sample_length)\n",
    "print(f\"Max source length: {max_source_length}\")\n",
    "\n",
    "# The maximum total sequence length for target text after tokenization. \n",
    "# Sequences longer than this will be truncated, sequences shorter will be padded.\"\n",
    "tokenized_targets = concatenate_datasets([dataset[\"train\"], dataset[\"test\"]]).map(lambda x: tokenizer(x[summary_column], truncation=True), batched=True, remove_columns=[text_column, summary_column])\n",
    "target_lenghts = [len(x) for x in tokenized_targets[\"input_ids\"]]\n",
    "# use 95th percentile as max target length\n",
    "max_target_length = int(np.percentile(target_lenghts, 95))\n",
    "print(f\"Max target length: {max_target_length}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç°åœ¨ä¸€åˆ‡å‡†å¤‡å°±ç»ªï¼Œå¯ä»¥å¤„ç†æ•°æ®é›†äº†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def preprocess_function(sample, padding=\"max_length\"):\n",
    "    # created prompted input\n",
    "    inputs = [prompt_template.format(input=item) for item in sample[text_column]]\n",
    "\n",
    "    # tokenize inputs\n",
    "    model_inputs = tokenizer(inputs, max_length=tokenizer.model_max_length, padding=padding, truncation=True)\n",
    "\n",
    "    # Tokenize targets with the `text_target` keyword argument\n",
    "    labels = tokenizer(text_target=sample[summary_column], max_length=max_target_length, padding=padding, truncation=True)\n",
    "\n",
    "    # If we are padding here, replace all tokenizer.pad_token_id in the labels by -100 when we want to ignore\n",
    "    # padding in the loss.\n",
    "    if padding == \"max_length\":\n",
    "        labels[\"input_ids\"] = [\n",
    "            [(l if l != tokenizer.pad_token_id else -100) for l in label] for label in labels[\"input_ids\"]\n",
    "        ]\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "# process dataset\n",
    "tokenized_dataset = dataset.map(preprocess_function, batched=True, remove_columns=list(dataset[\"train\"].features))\n",
    "\n",
    "# save dataset to disk\n",
    "tokenized_dataset[\"train\"].save_to_disk(os.path.join(save_dataset_path,\"train\"))\n",
    "tokenized_dataset[\"test\"].save_to_disk(os.path.join(save_dataset_path,\"eval\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä½¿ç”¨ `deepspeed` å¾®è°ƒæ¨¡å‹\n",
    "\n",
    "å‡†å¤‡å®Œæ¯•ï¼æˆ‘ä»¬ç°åœ¨å¯ä»¥å¼€å§‹è®­ç»ƒæ¨¡å‹äº†ï¼å¦‚å‰æ‰€è¿°ï¼Œæˆ‘ä»¬å°†ä½¿ç”¨é›†æˆäº† DeepSpeed çš„ Hugging Face Trainerã€‚å› æ­¤æˆ‘ä»¬éœ€è¦åˆ›å»ºä¸€ä¸ª `deespeed_config.json`ã€‚[DeepSpeed é…ç½®](https://www.deepspeed.ai/docs/config-json/) å®šä¹‰äº†è¦ä½¿ç”¨çš„ ZeRO ç­–ç•¥ä»¥åŠæ˜¯å¦è¦ä½¿ç”¨æ··åˆç²¾åº¦è®­ç»ƒç­‰é…ç½®é¡¹ã€‚ Hugging Face Trainer å…è®¸æˆ‘ä»¬ä» `deepspeed_config.json` ä¸­çš„ `TrainingArguments` ç»§æ‰¿ç›¸å…³é…ç½®ä»¥é¿å…é‡å¤è®¾ç½®ï¼ŒæŸ¥çœ‹ [æ–‡æ¡£äº†è§£æ›´å¤šä¿¡æ¯](https://huggingface.co/docs/transformers/v4.26.1/en/main_classes/deepspeed#configuration)ã€‚\n",
    "\n",
    "æˆ‘ä»¬åˆ›å»ºäº† 4 ç»„ deepspeed é…ç½®æ–‡ä»¶ç”¨äºå®éªŒï¼ŒåŒ…æ‹¬ `CPU å¸è½½` å’Œ `æ··åˆç²¾åº¦`:\n",
    "\n",
    "- [ds_flan_t5_z3_config.json](https://github.com/philschmid/deep-learning-pytorch-huggingface/blob/main/training/configs/ds_flan_t5_z3_config.json)\n",
    "- [ds_flan_t5_z3_config_bf16.json](https://github.com/philschmid/deep-learning-pytorch-huggingface/blob/main/training/configs/ds_flan_t5_z3_config_bf16.json)\n",
    "- [ds_flan_t5_z3_offload.json](https://github.com/philschmid/deep-learning-pytorch-huggingface/blob/main/training/configs/ds_flan_t5_z3_offload.json)\n",
    "- [ds_flan_t5_z3_offload_bf16.json](https://github.com/philschmid/deep-learning-pytorch-huggingface/blob/main/training/configs/ds_flan_t5_z3_offload_bf16.json)\n",
    "\n",
    "ä½ å¯ä»¥æ ¹æ®ä½ çš„è¿è¡Œç¯å¢ƒé€‰æ‹©ï¼Œä¾‹å¦‚å¦‚æœåœ¨ NVIDIA V100s ä¸Šè¿è¡Œï¼Œä½ å°±ä¸èƒ½ä½¿ç”¨å¸¦ `bf16` çš„é…ç½®ï¼Œå› ä¸º V100 ä¸æ”¯æŒ `bfloat16` æ•°æ®ç±»å‹ã€‚\n",
    "\n",
    "> åœ¨å¾®è°ƒ `T5` æ¨¡å‹æ—¶ï¼Œä¸èƒ½ä½¿ç”¨ `fp16`ï¼Œå› ä¸ºå®ƒä¼šå¯¼è‡´ç²¾åº¦æº¢å‡ºé—®é¢˜ï¼Œå‚è§é—®é¢˜  [#4586](https://github.com/huggingface/transformers/issues/4586)ï¼Œ[#10830](https://github.com/huggingface/transformers/issues/10830)ï¼Œå’Œæ‹‰å–è¯·æ±‚ [#10956](https://github.com/huggingface/transformers/pull/10956)\n",
    "\n",
    "å¦‚å¼€å¤´æ‰€è¿°ï¼Œæˆ‘ä»¬ä½¿ç”¨çš„æ˜¯ p4dn.24xlarge AWS EC2 å®ä¾‹ï¼Œè¯¥å®ä¾‹åŒ…å« 8 å¼ æ˜¾å­˜ä¸º 40GB çš„ NVIDIA A100ã€‚è¿™æ„å‘³ç€æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ `bf16`ï¼Œå®ƒå°†å‡å°‘è¿‘ä¸€åŠçš„æ¨¡å‹æ˜¾å­˜å ç”¨ï¼Œä½¿æˆ‘ä»¬èƒ½å¤Ÿåœ¨ä¸å¸è½½çš„æƒ…å†µä¸‹é«˜æ•ˆè®­ç»ƒã€‚\n",
    "\n",
    "æˆ‘ä»¬å°†ä½¿ç”¨ [ds_flan_t5_z3_config_bf16.json](https://github.com/philschmid/deep-learning-pytorch-huggingface/blob/main/training/configs/ds_flan_t5_z3_config_bf16.json)ã€‚å¦‚æœä½ ä¸æƒ³ç”¨ `auto` å€¼ï¼Œå¯ä»¥æŸ¥çœ‹ [æ–‡æ¡£](https://huggingface.co/docs/transformers/v4.26.1/en/main_classes/deepspeed#configuration)ã€‚\n",
    "\n",
    "ç°åœ¨ï¼Œè¯¥è®­ç»ƒè„šæœ¬ä¸Šåœºäº†ã€‚æˆ‘ä»¬æ ¹æ® [Fine Tune FLAN-T5](https://www.philschmid.de/fine-tune-flan-t5) å‡†å¤‡äº†ä¸€ä¸ª [run_seq2seq_deepspeed.py](https://github.com/philschmid/deep-learning-pytorch-huggingface/blob/main/training/scripts/run_seq2seq_deepspeed.py) è®­ç»ƒè„šæœ¬ï¼Œå®ƒæ”¯æŒæˆ‘ä»¬é…ç½® deepspeed å’Œå…¶ä»–è¶…å‚æ•°ï¼ŒåŒ…æ‹¬ `google/flan-t5-xxl` çš„æ¨¡å‹ IDã€‚\n",
    "\n",
    "æˆ‘ä»¬ä½¿ç”¨ `deepspeed` å¯åŠ¨å™¨è§¦å‘è®­ç»ƒï¼Œè¾“å…¥ç»™å¯åŠ¨å™¨çš„å‚æ•°åŒ…æ‹¬ GPU æ•°é‡ã€deepspeed é…ç½®åŠå…¶å®ƒè¶…å‚æ•° (å¦‚ `google/flan-t5-xxl` çš„æ¨¡å‹ ID)ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "deepspeed --num_gpus=8 scripts/run_seq2seq_deepspeed.py --model_id google/flan-t5-xxl --dataset_path data --epochs 3 --per_device_train_batch_size 8 --per_device_eval_batch_size 8 --generation_max_length 129 --lr 1e-4 --deepspeed configs/ds_flan_t5_z3_config_bf16.json\n"
     ]
    }
   ],
   "source": [
    "!deepspeed --num_gpus=8 scripts/run_seq2seq_deepspeed.py \\\n",
    "    --model_id $model_id \\\n",
    "    --dataset_path $save_dataset_path \\\n",
    "    --epochs 3 \\\n",
    "    --per_device_train_batch_size 8 \\\n",
    "    --per_device_eval_batch_size 8 \\\n",
    "    --generation_max_length $max_target_length \\\n",
    "    --lr 1e-4 \\\n",
    "    --deepspeed configs/ds_flan_t5_z3_config_bf16.json "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DeepSpeed ä¼šå…ˆå°†æ¨¡å‹åŠ è½½åˆ° CPU ä¸Šï¼Œç„¶åå°†å…¶æ‹†åˆ†åˆ° 8 å¼  A100 ä¸Šç„¶åå¼€å§‹è®­ç»ƒã€‚ä½¿ç”¨ [CNN Dailymail æ•°æ®é›†](https://huggingface.co/datasets/cnn_dailymail) è¿›è¡Œè®­ç»ƒå¤§çº¦éœ€è¦ 10 ä¸ªå°æ—¶ï¼Œè´¹ç”¨çº¦ä¸º `322 ç¾å…ƒ`ã€‚"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ç»“æœä¸å®éªŒ\n",
    "\n",
    "ä¸ºäº†æ›´å¥½åœ°äº†è§£ç¡¬ä»¶è¦æ±‚ï¼Œæˆ‘ä»¬å¯¹ FLAN-T5 XL å’Œ XXL è¿›è¡Œäº†ä¸€ç³»åˆ—å®éªŒï¼Œä»¥å¸®åŠ©æˆ‘ä»¬è¯„ä¼°å’Œäº†è§£ç¡¬ä»¶éœ€æ±‚ä»¥åŠè®­ç»ƒè¿™äº›æ¨¡å‹çš„æˆæœ¬ã€‚\n",
    "\n",
    "ä¸‹è¡¨åˆ—å‡ºäº†å®éªŒå’Œç›¸å…³è®¾ç½®çš„è¯¦ç»†ä¿¡æ¯ã€‚\n",
    "\n",
    "æ•°æ®é›†: `\"cnn_dailymail\"`\n",
    "- è®­ç»ƒæ ·æœ¬æ•°: `287113`\n",
    "- éªŒè¯æ ·æœ¬æ•°: `13368`\n",
    "\n",
    "è¶…å‚:\n",
    "- epochs: `3`\n",
    "- å­¦ä¹ ç‡: `1e-4`\n",
    "\n",
    "è¿è¡Œç¯å¢ƒè®¾ç½®:\n",
    "- 4x V100 16GB: p3.8xlarge\n",
    "- 4x A10G 24GB: g5.24xlarge\n",
    "- 8x V100 16GB: p3.16xlarge\n",
    "- 8x A100 40GB: p4dn.24xlarge\n",
    "\n",
    "| æ¨¡å‹              | DeepSpeed å¸è½½ | ç¡¬ä»¶       | GPUæ¯å¡batch size   | ç²¾åº¦       | æ—¶é•¿     | è´¹ç”¨    |\n",
    "|-------------------|------------|--------------|--------------------|-----------|----------|--------|\n",
    "| FLAN-T5-XL (3B)   | No         | 4x V100 16GB | OOM                | fp32      | -        | -      |\n",
    "| FLAN-T5-XL (3B)   | No         | 8x V100 16GB | 1                  | fp32      | 105h     | ~$2570 |\n",
    "| FLAN-T5-XL (3B)   | No         | 8x A100 40GB | 72                 | bf16     |   2,5h       | ~$81       |\n",
    "| FLAN-T5-XL (3B)   | Yes        | 4x V100 16GB | 8                  | fp32      | 69h      | ~$828  |\n",
    "| FLAN-T5-XL (3B)   | Yes        | 8x V100 16GB | 8                  | fp32      | 32h      | ~$768  |\n",
    "| FLAN-T5-XXL (11B) | No        | 8x A100 40GB | 8                | bf16      | 10h        | ~$322      |\n",
    "| FLAN-T5-XXL (11B) | Yes        | 4x V100 16GB | OOM                | fp32      | -        | -      |\n",
    "| FLAN-T5-XXL (11B) | Yes        | 8x V100 16GB | OOM                | fp32      | -        | -      |\n",
    "| FLAN-T5-XXL (11B) | Yes        | 4x A10G 24GB | 24                | bf16      | 90h      | ~$732  |\n",
    "| FLAN-T5-XXL (11B) | Yes        | 8x A100 40GB | 48                | bf16      | 19h      | ~$613  |"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬å¯ä»¥çœ‹åˆ° `bf16` ä¸  `fp32` ç›¸æ¯”å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿ã€‚FLAN-T5-XXL èƒ½æ”¾è¿› 4 å¼  A10G (24GB)ï¼Œä½†æ”¾ä¸è¿› 8 å¼  V100 16GBã€‚\n",
    "\n",
    "æˆ‘ä»¬çš„å®éªŒè¿˜è¡¨æ˜ï¼Œå¦‚æœæ¨¡å‹å¯ä»¥æ— éœ€å¸è½½åŒæ—¶ä»¥ batch size å¤§äº 4 çš„é…ç½®è·‘åœ¨ GPU ä¸Šï¼Œå…¶é€Ÿåº¦å°†æ¯”å¸è½½æ¨¡å‹å’Œå‡å° batch size çš„é…ç½®å¿«çº¦ 2 å€ä¸”æ›´å…·æˆæœ¬æ•ˆç›Šã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2d58e898dde0263bc564c6968b04150abacfd33eed9b19aaa8e45c040360e146"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
